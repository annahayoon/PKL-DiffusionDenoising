# Configuration for PKL Diffusion Denoising with Adaptive Normalization
# This configuration demonstrates how to use adaptive normalization for better
# dynamic range utilization and improved DDPM training performance.

experiment:
  name: "adaptive_normalization_ddpm"
  device: "auto"
  seed: 42

# Data configuration with adaptive normalization
data:
  _target_: pkl_dg.data.adaptive_dataset.AdaptiveRealPairsDataset
  use_adaptive_normalization: true
  adaptive:
    percentiles: [0.1, 99.9]  # Use 0.1-99.9 percentile range for normalization
  image_size: 512
  noise_model: "gaussian"
  min_intensity: 0.0
  max_intensity: 65535.0

# Model configuration
model:
  _target_: pkl_dg.models.unet.UNet
  in_channels: 2  # x_t + WF conditioner for adaptive normalization
  out_channels: 1
  base_channels: 128
  num_res_blocks: 2
  attention_resolutions: [16, 8]
  dropout: 0.1

# Training configuration
training:
  max_epochs: 100
  batch_size: 8
  learning_rate: 1e-4
  weight_decay: 1e-4
  num_workers: 4
  use_conditioning: true
  conditioning_type: "wf"
  num_timesteps: 1000
  
  # Early stopping
  early_stopping_patience: 25
  early_stopping_min_delta: 1e-5
  
  # Checkpointing
  save_every_n_epochs: 10
  
  # Mixed precision for faster training
  precision: "16-mixed"
  gradient_clip_val: 1.0

# Paths
paths:
  data: "data/real_microscopy"
  checkpoints: "checkpoints/adaptive_normalization"
  logs: "logs"
  outputs: "outputs"

# Physics model for forward simulation
physics:
  use_psf: true
  use_bead_psf: true
  beads_dir: "data/beads"
  bead_mode: "with_AO"
  background: 0.0
  target_pixel_size_xy_nm: 65.0

# PSF fallback configuration
psf:
  type: "gaussian"
  size: 21
  sigma_x: 2.0
  sigma_y: 2.0

# Guidance configuration
guidance:
  lambda_guidance: 1.0
  guidance_scale: 1.0

# W&B logging
wandb:
  project: "pkl-diffusion-denoising"
  entity: null
  mode: "online"  # "online", "offline", or "disabled"
