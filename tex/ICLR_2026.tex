% ICLR 2025 submission
\documentclass{article}
\usepackage{iclr2026_conference,times}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{siunitx}
\usepackage{hyperref}

% --- Custom Commands ---
\newcommand{\wf}{WF\xspace}
\newcommand{\twop}{2P\xspace}
\newcommand{\methodname}{Poisson-aware Diffusion Guidance\xspace}
\newcommand{\methodacr}{PKL-DG\xspace}

% --- Switches ---
\newif\ifuseDDIMfile
\useDDIMfiletrue % set to \useDDIMfiletrue to include tex/DDIM.tex

% --- Document Title ---
\title{Microscopy Denoising Diffusion with Poisson-aware Physical Guidance}

\author{Anonymous Authors\\
Anonymous Institution}

\begin{document}
\maketitle

% --- Abstract ---
\begin{abstract}
Denoising diffusion models can solve imaging inverse problems by guiding the sampling process to remain consistent with a physical forward model. Standard practice dictates an L$_2$ norm for this data consistency term, which implicitly assumes Gaussian noise. This assumption is a poor match for photon-limited imaging, such as fluorescence microscopy, where noise is signal-dependent and accurately described by a Poisson distribution. This statistical mismatch leads to reconstruction artifacts, particularly in low-count regimes critical for biological imaging. We address this fundamental issue by proposing a novel, physically-motivated guidance mechanism based on the Kullback-Leibler (KL) divergence, the natural discrepancy measure for Poisson statistics. Our Poisson-Kullback-Leibler (PKL) guidance employs an adaptive, per-pixel update rule derived from the measurement's statistical properties, enabling strong corrections in photon-starved regions while preventing over-smoothing in bright areas. We validate our method on the challenging task of transforming blurry, noisy widefield microscopy acquisitions into high-resolution, optically-sectioned two-photon quality reconstructions. Through a suite of adversarial evaluations, we demonstrate that PKL guidance significantly outperforms both the standard L$_2$-guided approach and a stronger baseline using a variance-stabilizing Anscombe transform. Our work establishes a more principled, robust, and effective framework for guiding generative models in any Poisson-noise-dominated scientific domain.
\end{abstract}

% --- Introduction ---
\section{Introduction}
\label{sec:intro}
Denoising diffusion probabilistic models (DDPMs) have emerged as a powerful class of generative priors for solving inverse problems across scientific imaging domains~\cite{ho2020ddpm, song2022solving}. A prevalent strategy is to steer an unconditionally trained model's sampling trajectory towards solutions that are consistent with a physical measurement $\mathbf{y}$~\cite{chung2022diffusion}. This data-consistency step is typically implemented by taking the gradient of a loss function, most often the L$_2$ norm (i.e., Mean Squared Error), $\|\mathbf{y} - \mathcal{A}(\mathbf{x})\|^2$, where $\mathcal{A}$ is the physical forward operator.

While effective, the L$_2$ norm's implicit assumption of homoscedastic Gaussian noise represents a critical limitation. In many scientific fields, from astronomical imaging to medical PET scans, the measurement noise is fundamentally non-Gaussian. A prime example is fluorescence microscopy, where the discrete arrival of photons is a Poisson process. In this regime, the noise variance is equal to the signal intensity itself. Applying an L$_2$ norm, which penalizes all deviations equally regardless of signal strength, is therefore physically mismatched. This approach tends to over-penalize deviations in bright, high-variance regions and under-correct faint, photon-starved structures, ultimately degrading reconstruction fidelity.

Our primary contribution is a new guidance mechanism for diffusion models that respects the underlying photon statistics of the imaging process. We replace the mismatched L$_2$ data-consistency term with one based on the Kullback-Leibler (KL) divergence, which serves as the Bregman divergence generated by the negative Poisson log-likelihood. This Poisson-Kullback-Leibler (PKL) guidance yields a simple and intuitive update rule that automatically adapts the correction strength at each pixel in inverse proportion to the predicted signal intensity. For improved physical accuracy, our forward model also incorporates a measured detector background term, a pragmatic step to account for experimental non-idealities.

To validate our approach, we tackle the challenging problem of computational optical sectioning: transforming blurry widefield (\wf) microscopy images into high-resolution, optically-sectioned two-photon (\twop) quality reconstructions. This task is crucial for neuroscience, as it promises to combine the speed and field-of-view of \wf imaging with the resolution of \twop microscopy.

Crucially, we evaluate our PKL-guided diffusion model not only against the standard L$_2$-norm baseline but also against a more sophisticated competitor: L$_2$ guidance applied in an Anscombe-transformed space, a classic technique for variance stabilization of Poisson data. Our experiments are designed to be adversarial, probing for common failure modes such as robustness to deliberate model mismatch and the propensity to hallucinate features.

Our contributions are threefold:
\begin{enumerate}
    \item We introduce Poisson-Kullback-Leibler (PKL) guidance, a novel, physically-grounded, and adaptive data-consistency mechanism for denoising diffusion models in Poisson-noise-dominated applications.
    \item We demonstrate on a challenging scientific task that PKL guidance achieves state-of-the-art reconstruction fidelity, outperforming both standard L$_2$ guidance and a strong Anscombe-transformed L$_2$ baseline.
    \item We execute a rigorous, adversarial evaluation protocol that measures robustness to model mismatch and quantifies model hallucination, setting a higher standard for validating generative models in scientific applications.
\end{enumerate}


% --- Methodology ---
\section{Methodology}
\label{sec:methodology}
Our method combines an unconditionally trained DDPM, which serves as a powerful generative prior for high-quality microscopy images, with a novel guidance mechanism applied at inference time.

\subsection{Physical Forward Model}
Let $\mathbf{x} \in \mathbb{R}_+^{H \times W}$ be the clean, high-resolution (e.g., \twop) image representing expected photon rates. Let $\mathbf{y} \in \mathbb{N}^{H \times W}$ be the measured low-quality (e.g., \wf) image, composed of integer photon counts. We model the acquisition process as:
\begin{equation}
\mathbf{y} \sim \text{Poisson}(\mathcal{A}(\mathbf{x}) + B)
\end{equation}
where $\mathcal{A}(\cdot)$ is a linear operator representing system blur (e.g., convolution with a Point Spread Function, PSF), and $B$ is a measured scalar value representing the average detector dark counts and background fluorescence. Raw measurements $\mathbf{y}$ are kept as integer counts to preserve their natural statistics. The diffusion model is trained on ground-truth images $\mathbf{x}$ normalized to $[-1,1]$ for stability. During inference, the model's prediction of a clean image, $\mathbf{\hat{x}}_0$, is de-normalized to a non-negative intensity scale before being used in the forward model.

\subsection{Diffusion Model Preliminaries}
Following standard DDPM formulation, we define a reverse sampling process that iteratively denoises a sample $\mathbf{x}_t$ from a Gaussian distribution to produce a clean image $\mathbf{x}_0$. At each timestep $t$, the model $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$ predicts the noise added to the image. From this, we can derive an estimate of the clean image $\mathbf{\hat{x}}_0$:
\begin{equation}
    \mathbf{\hat{x}}_0(\mathbf{x}_t, t) = \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\right)
\end{equation}
This estimate $\mathbf{\hat{x}}_0$ is then corrected to enforce consistency with the physical measurement $\mathbf{y}$.

\subsection{Physics-Informed Guidance Mechanisms}
We compare three primary guidance mechanisms for correcting $\mathbf{\hat{x}}_0$.

\paragraph{1. Standard L$_2$ Guidance (Baseline):} This common approach assumes Gaussian noise and computes a correction based on the L$_2$ norm gradient:
\begin{equation}
\nabla_{\text{L2}} = \mathcal{A}^T(\mathbf{y} - (\mathcal{A}(\mathbf{\hat{x}}_0) + \mathbf{B}))
\end{equation}

\paragraph{2. Anscombe+L$_2$ Guidance (Strong Baseline):} To better handle Poisson statistics, this baseline first applies the variance-stabilizing Anscombe transform, $f(z) = 2\sqrt{z + 3/8}$, before applying L$_2$ guidance:
\begin{equation}
\nabla_{\text{Anscombe}} = \mathcal{A}^T \nabla_{\mathbf{x}} \|f(\mathbf{y}) - f(\mathcal{A}(\mathbf{\hat{x}}_0) + \mathbf{B})\|^2
\end{equation}

\paragraph{3. Proposed PKL Guidance:} Our method replaces the mismatched L$_2$ norm with the KL divergence, $D_{KL}(p||q) = \sum_i (p_i \log(p_i/q_i) - p_i + q_i)$, which is the statistically appropriate divergence for Poisson distributions. The resulting gradient for our guidance is (with an optional read-noise-aware background term retained in $\mathbf{B}$):
\begin{equation}
\nabla_{\text{PKL}} = \mathcal{A}^T \left( 1 - \frac{\mathbf{y}}{\mathcal{A}(\mathbf{\hat{x}}_0) + \mathbf{B} + \epsilon} \right)
\end{equation}
where $\epsilon$ is a small constant for numerical stability. This update rule is remarkably intuitive: the correction term, $1 - \mathbf{y}/\mathcal{A}(\mathbf{x})$, scales the update at each pixel inversely with the expected signal strength, naturally adapting to the signal-dependent nature of Poisson noise.

\subsection{Adaptive Guidance Schedule}
The performance of guided diffusion is highly sensitive to the guidance strength schedule, $\lambda_t$. We employ a principled schedule designed for stability and effectiveness across all three methods to ensure a fair comparison. The corrected estimate $\mathbf{\hat{x}}'_0$ is computed as:
\begin{equation}
\mathbf{\hat{x}}'_0 = \mathbf{\hat{x}}_0 - \lambda_t \cdot \nabla
\end{equation}
where the schedule $\lambda_t$ is defined as:
\begin{equation}
\lambda_t = \frac{\lambda_{\text{base}}}{\|\nabla\|_2 + \epsilon_\lambda} \cdot \min\left(\frac{T-t}{T-T_{\text{thr}}}, 1.0\right)
\end{equation}
The intuition is twofold:

\textbf{Adaptive Step Size:} The $\frac{\lambda_{\text{base}}}{\|\nabla\|_2 + \epsilon_\lambda}$ term normalizes the gradient, ensuring a consistent step size controlled by a single intuitive hyperparameter, $\lambda_{\text{base}}$. This prevents explosive updates, a common failure mode when the gradient magnitude varies wildly.

\textbf{Guidance Warm-up:} The $\min(\cdot)$ term gradually ramps up the guidance strength. At the beginning of sampling (large $t$, near $T$), when the estimate $\mathbf{\hat{x}}_0$ is unreliable, guidance is weak. It reaches full strength only after $t$ drops below a threshold $T_{\text{thr}}$, preventing the model from over-committing to the measurement based on early, noisy predictions.

\subsection{Theoretical Analysis}

\paragraph{Convergence Properties.} Unlike L$_2$ guidance, which can exhibit unstable behavior in low-signal regimes, our PKL guidance provides natural regularization through the Poisson likelihood structure. The correction term $1 - \mathbf{y}/(\mathcal{A}(\mathbf{\hat{x}}_0) + \mathbf{B})$ is bounded for any positive signal, ensuring stable convergence to a statistically meaningful solution.

\paragraph{Bias-Variance Analysis.} The adaptive nature of PKL guidance leads to favorable bias-variance properties: in high-photon regimes where $\mathcal{A}(\mathbf{\hat{x}}_0) \gg \mathbf{y}$, the correction term approaches zero, reducing variance while maintaining low bias. In low-photon regimes where $\mathcal{A}(\mathbf{\hat{x}}_0) \approx \mathbf{y}$, stronger corrections preserve signal recovery at the cost of slightly increased varianceâ€”an optimal trade-off for Poisson-distributed data. This automatic adaptation eliminates the need for manual hyperparameter tuning across different signal conditions.

% --- Experimental Design ---
\section{Experimental Design}
\label{sec:experiments}
Our evaluation protocol is designed to rigorously compare the three guidance mechanisms, with a focus on scientific utility and robustness.

\subsection{Data and Model Details}
\textbf{Dataset:} Our training and test sets consist of [{\# of image pairs}] registered pairs of widefield ($\mathbf{y}$) and two-photon ($\mathbf{x}$) images of GCaMP6s-expressing neurons in the mouse brain.

\textbf{Training Data Synthesis:} To generate a simulated dataset for training our models, we utilized photographs from an ImageNet-like collection of license-friendly images. Each image was processed through a forward microscopy model, termed the Image Acquisition Model (\wf $\rightarrow$ \twop). This model simulates the effects of \wf and \twop microscopes by convolving each image with a Point Spread Function (PSF), then applying Poisson noise and adding a Gaussian background term to mimic out-of-fluorescence background.

\textbf{Physical Model Parameters:} The PSF for the operator $\mathcal{A}$ and the background term $B$ were empirically measured from images of sub-diffraction fluorescent beads and blank fields of view, respectively.

\textbf{Implementation:} Our unconditional diffusion model uses a standard U-Net architecture. It was trained for [{\# of epochs}] on 256$\times$256 pixel patches. Inference was performed using a DDIM sampler with 100 steps. The guidance hyperparameter $\lambda_{\text{base}}$ was tuned for each method on a validation set.

\subsection{Models for Comparison}
We compare our proposed PKL-guided model against four baselines:
\begin{itemize}
\item \textbf{Richardson-Lucy Deconvolution:} A classical iterative algorithm based on a Poisson noise model.
\item \textbf{RCAN:} A state-of-the-art supervised CNN for image restoration, trained end-to-end on the (\wf, \twop) pairs.
\item \textbf{L$_2$-guided Diffusion:} Our diffusion model using standard L$_2$ guidance.
\item \textbf{Anscombe+L$_2$-guided Diffusion:} Our diffusion model using the Anscombe-stabilized L$_2$ guidance.
\end{itemize}

\subsection{Evaluation Protocol \& Results}

\subsubsection{Reconstruction Fidelity and Resolution}
We first assess standard image quality metrics. As shown in Table~1, our PKL guidance achieves the highest performance across all metrics. In particular, the Fourier Ring Correlation (FRC) score, which measures effective image resolution, shows a significant improvement, indicating a superior recovery of fine details. Figure~1 provides a visual comparison, highlighting PKL's ability to resolve fine neural processes that are lost or distorted by other methods.

\textbf{[Table 1: Quantitative comparison of reconstruction fidelity. Columns: Method, PSNR$\uparrow$, SSIM$\uparrow$, FRC (resolution in nm)$\downarrow$. Rows: WF Input, RL, RCAN, L$_2$, Anscombe+L$_2$, PKL (ours).]}

\textbf{[Figure 1: Visual comparison on a representative test image. Show a difficult region with both bright somas and faint dendrites. Columns: WF Input, Ground Truth, L$_2$, Anscombe+L$_2$, PKL (ours).]}

\subsubsection{Downstream Scientific Task Performance}
To measure scientific utility, we performed two task-based evaluations. First, we ran a pre-trained instance segmentation model (Cellpose~\cite{stringer2021cellpose}) on the reconstructions. Table~2 shows that PKL-reconstructed images yield the highest F1-score for neuron detection. Second, we measured the morphological accuracy of segmented neurons using the Hausdorff distance to the ground truth segmentation. PKL guidance again provides the most accurate morphological reconstructions.

\textbf{[Table 2: Downstream task performance. Columns: Method, Cellpose F1-Score$\uparrow$, Mean Hausdorff Distance$\downarrow$. Rows for all methods.]}

\subsubsection{Robustness to Model Mismatch}
A key claim of ``physics-informed'' models is robustness. We tested this by intentionally introducing two common sources of experimental error.

\textbf{PSF Mismatch:} We performed inference using a PSF that was artificially broadened by 10\%.

\textbf{Alignment Error:} We evaluated all models on our test set using the raw, imperfectly registered image pairs, which have a mean registration error of [$\sim$0.5-1.0 pixels].

Figure~2 shows that while all physics-based methods degrade, PKL guidance exhibits the most graceful degradation, producing significantly fewer artifacts than L$_2$ and Anscombe+L$_2$ methods, demonstrating its superior robustness.

\textbf{[Figure 2: Robustness to model mismatch. Show a grid of results. Rows: Correct PSF, Mismatched PSF, Misaligned Data. Columns: L$_2$, Anscombe+L$_2$, PKL (ours). Highlight the artifacts produced by the baselines.]}

\subsubsection{Adversarial Analysis of Hallucination}
Finally, we performed two tests to probe for model hallucination.

\textbf{Test for Commission Error:} We digitally added a bright, out-of-focus artifact to input \wf images that had no corresponding \twop structure. We measured the Signal-to-Artifact Ratio (SAR) in the output. A higher SAR indicates less hallucination.

\textbf{Test for Omission/Normalization Error:} We created semi-synthetic data by adding a small, faint, but biologically plausible structure to the \twop ground truth and generating its corresponding \wf measurement. We measured the reconstruction fidelity of this specific structure.

As reported in Table~3, the PKL-guided model exhibits a significantly higher SAR, indicating it is less likely to create features from noise. Furthermore, it demonstrates superior fidelity in reconstructing the faint, atypical structure, suggesting its powerful prior is less likely to suppress or ``normalize'' unexpected biological features.

\textbf{[Table 3: Adversarial hallucination analysis. Columns: Method, SAR$\uparrow$, Atypical Structure Fidelity (PSNR)$\uparrow$. Rows for all diffusion methods.]}


% --- Discussion and Limitations ---
\section{Discussion and Limitations}
\label{sec:limitations}
Our results consistently demonstrate that respecting the underlying Poisson statistics of the measurement process via PKL guidance leads to marked improvements in reconstruction fidelity, scientific utility, and model robustness. The adaptive nature of the PKL update rule allows the model to confidently correct low-signal regions without introducing the over-smoothing artifacts in high-signal regions that plague the L$_2$ and Anscombe baselines. This work provides a clear path forward for applying diffusion models to a wide range of scientific inverse problems where Gaussian noise assumptions do not hold.

Our method has three primary limitations. First, guided diffusion is computationally more expensive at inference than a single pass through a feed-forward network like RCAN. Second, our background-aware Poisson model is a pragmatic simplification; it neglects other noise sources like Gaussian read noise. Third, our forward model simplifies light-tissue interaction to a spatially invariant convolution, ignoring complex, spatially varying scattering. Our robustness experiments were designed to test the model's performance when this simplification is violated, but more advanced forward models represent an important direction for future work.

% --- Conclusion ---
\section{Conclusion}
\label{sec:conclusion}
We have introduced Poisson-Kullback-Leibler (PKL) guidance, a novel mechanism for denoising diffusion models that replaces the standard L$_2$-norm with a physically appropriate KL divergence term. Through a series of adversarial experiments, we demonstrated that our approach achieves state-of-the-art performance on a challenging microscopy image restoration task, exhibiting superior robustness to model mismatch and a lower tendency to hallucinate artifacts compared to both standard and variance-stabilized baselines. PKL guidance provides a generalizable framework for principled, physics-aware generative image restoration in any Poisson-noise-dominated modality.

\subsubsection*{Reproducibility Statement}
The code for data processing, model training, and the full evaluation protocol will be made publicly available upon publication. All hyperparameters and experimental details will be provided in the final manuscript.

\bibliographystyle{iclr2026_conference}
\bibliography{bibliography}

\end{document}